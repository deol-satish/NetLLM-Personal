{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial - Save Model and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deols\\anaconda3\\envs\\urllc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\deols\\anaconda3\\envs\\urllc\\lib\\site-packages\\transformers\\generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "from pprint import pprint\n",
    "from munch import Munch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from config import cfg\n",
    "from baseline_special.utils.utils import load_traces\n",
    "from baseline_special.utils.constants import BITRATE_LEVELS\n",
    "from plm_special.trainer import Trainer\n",
    "from plm_special.evaluate import evaluate_on_env\n",
    "from plm_special.test import test_on_env\n",
    "from plm_special.data.dataset import ExperienceDataset\n",
    "from plm_special.models.rl_policy import OfflineRLPolicy\n",
    "from plm_special.models.state_encoder import EncoderNetwork\n",
    "from plm_special.models.low_rank import peft_model\n",
    "from plm_special.utils.utils import set_random_seed\n",
    "from plm_special.utils.plm_utils import load_plm\n",
    "from plm_special.utils.console_logger import ConsoleLogger\n",
    "\n",
    "\n",
    "PLM_LAYER_SIZES = {\n",
    "    'gpt2': {\n",
    "        'base': 24,\n",
    "        'small': 12,\n",
    "        'large': 36,\n",
    "        'xl': 48\n",
    "    },\n",
    "    'llama': {\n",
    "        'base': 32,\n",
    "    },\n",
    "    't5-lm': { \n",
    "        'base': 12,\n",
    "        'small': 6,\n",
    "        'large': 24,\n",
    "        'xl': 24\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def save_model(args, model, save_dir):\n",
    "    if args.rank > 0:\n",
    "        # save lora weights\n",
    "        model.plm.save_pretrained(save_dir)\n",
    "        # save other modules except plm\n",
    "        torch.save(model.modules_except_plm.state_dict(), os.path.join(save_dir, 'modules_except_plm.bin'))\n",
    "    else:\n",
    "        # lora is disabled, save whole model\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, 'model.bin'))\n",
    "\n",
    "\n",
    "def load_model(args, model, model_dir):\n",
    "    if args.rank > 0:\n",
    "        # load lora weights\n",
    "        model.plm.load_adapter(model_dir, adapter_name='default')\n",
    "        # load other modules except plm\n",
    "        model.modules_except_plm.load_state_dict(torch.load(os.path.join(model_dir, 'modules_except_plm.bin')))\n",
    "    else:\n",
    "        # lora is disabled, load whole model\n",
    "        model.load_state_dict(torch.load(os.path.join(model_dir, 'model.bin')))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt/fine-tune model/train mdoel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt(args, model, exp_dataset, exp_dataset_info, eval_env_settings, checkpoint_dir, best_model_dir, eval_process_reward_fn):\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=args.lr,\n",
    "        weight_decay=args.weight_decay,\n",
    "    )\n",
    "    lr_scheduler = LambdaLR(\n",
    "        optimizer,\n",
    "        lambda steps: min((steps + 1) / args.warmup_steps, 1)\n",
    "    )\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    trainer = Trainer(args, model=model, optimizer=optimizer, exp_dataset=exp_dataset, loss_fn=loss_fn, device=args.device, lr_scheduler=lr_scheduler, \n",
    "                      grad_accum_steps=args.grad_accum_steps)\n",
    "\n",
    "    target_return = exp_dataset_info.max_return * args.target_return_scale\n",
    "    best_eval_return = 0.\n",
    "\n",
    "    total_train_losses = []\n",
    "    for epoch in range(args.num_epochs):\n",
    "        train_logs, train_losses = trainer.train_epoch()\n",
    "        total_train_losses.extend(train_losses)\n",
    "        print('='* 20, f'Training Iteration #{epoch}', '=' * 20)\n",
    "        print('>' * 10, 'Training Information:')\n",
    "        pprint(train_logs)\n",
    "\n",
    "        if epoch % args.save_checkpoint_per_epoch == 0:  # save checkpoint\n",
    "            checkpoint_dir_epoch = os.path.join(checkpoint_dir, str(epoch))\n",
    "            if not os.path.exists(checkpoint_dir_epoch):\n",
    "                os.makedirs(checkpoint_dir_epoch)\n",
    "            save_model(args, model, checkpoint_dir_epoch)\n",
    "            print('Checkpoint saved at:', checkpoint_dir_epoch)\n",
    "\n",
    "        if epoch % args.eval_per_epoch == 0:\n",
    "            eval_logs = evaluate_on_env(args, env_settings=eval_env_settings, model=model, target_return=target_return, max_ep_num=args.trace_num,\n",
    "                                        process_reward_fn=eval_process_reward_fn)\n",
    "            episodes_return = eval_logs['episodes_return']\n",
    "            if best_eval_return < episodes_return:\n",
    "                best_eval_return = episodes_return\n",
    "                save_model(args, model, best_model_dir)\n",
    "                print('Best model saved at:', best_model_dir)\n",
    "\n",
    "            eval_logs['best_return'] = best_eval_return\n",
    "            print('>' * 10, 'Evaluation Information')\n",
    "            pprint(eval_logs)\n",
    "    # save training losses\n",
    "    train_losses_path = os.path.join(checkpoint_dir, 'train_losses.txt')\n",
    "    np.savetxt(train_losses_path, total_train_losses, fmt='%.6f', delimiter='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, exp_dataset_info, env_settings, model_dir, result_dir, test_process_reward_fn):\n",
    "    model = load_model(args, model, model_dir)\n",
    "    print('Load model from:', model_dir)\n",
    "    target_return = exp_dataset_info.max_return * args.target_return_scale\n",
    "    results = test_on_env(args, model, result_dir, env_settings, target_return, args.trace_num, test_process_reward_fn, seed=args.seed)\n",
    "    print(results)\n",
    "    print('Test time:', results['time'], '\\nMean reward:', results['mean_reward'])\n",
    "    print('Results saved at:', result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args):\n",
    "    assert args.plm_type in cfg.plm_types\n",
    "    assert args.plm_size in cfg.plm_sizes\n",
    "    assert args.exp_pool_path is not None, 'please specify a experience pool path for training'\n",
    "    assert args.trace in cfg.trace_dirs.keys()\n",
    "    assert args.video in cfg.video_size_dirs.keys()\n",
    "\n",
    "    # 1. set seed\n",
    "    set_random_seed(args.seed)\n",
    "\n",
    "    # 2. create environment setting\n",
    "    trace_dir = cfg.trace_dirs[args.trace]\n",
    "    video_size_dir = cfg.video_size_dirs[args.video]\n",
    "    all_cooked_time ,all_cooked_bw ,all_file_names, all_mahimahi_ptrs = load_traces(trace_dir)\n",
    "    args.trace_num = min(args.trace_num, len(all_file_names))\n",
    "    if args.trace_num == -1:\n",
    "        args.trace_num = len(all_file_names)\n",
    "    if args.trace_num == len(all_file_names):\n",
    "        args.fixed_order = True\n",
    "\n",
    "    env_settings = {\n",
    "        'all_cooked_time': all_cooked_time,\n",
    "        'all_cooked_bw': all_cooked_bw,\n",
    "        'all_file_names': all_file_names,\n",
    "        'all_mahimahi_ptrs': all_mahimahi_ptrs,\n",
    "        'video_size_dir': video_size_dir,\n",
    "        'fixed': args.fixed_order,\n",
    "        'trace_num': args.trace_num,\n",
    "    }\n",
    "\n",
    "    # 3. create training dataset, fetch info\n",
    "    exp_pool = pickle.load(open(args.exp_pool_path, 'rb'))\n",
    "    exp_dataset = ExperienceDataset(exp_pool, gamma=args.gamma, scale=args.scale, max_length=args.w, sample_step=args.sample_step)\n",
    "    print(\"exp_dataset\",exp_dataset)\n",
    "    exp_dataset_info = Munch(exp_dataset.exp_dataset_info)\n",
    "    print('Experience dataset info:')\n",
    "    pprint(exp_dataset_info)\n",
    "    \n",
    "    # 4. create model\n",
    "    \n",
    "    # 4.1 load plm\n",
    "    # args.device_out and args.device_mid are used for model parallelism (currently only support llama) \n",
    "    # For data/modules near the input side, we use args.device.\n",
    "    # For data/modules near the output side, we use args.device_out.\n",
    "    # For data/modules lying in the middle, we use args.device_mid (it can be None). \n",
    "    # If args.device == args.device_out == args.device_mid (if not None), everything will be the same as using only one device.\n",
    "    plm, *_ = load_plm(args.plm_type, os.path.join(cfg.plm_dir, args.plm_type, args.plm_size), \n",
    "                       device_input_side=args.device, device_output_side=args.device_out, device_middle_side=args.device_mid)\n",
    "\n",
    "    if args.plm_type != 'llama':\n",
    "        plm = plm.to(args.device)\n",
    "    \n",
    "    if args.rank != -1:\n",
    "        plm = peft_model(plm, args.plm_type, rank=args.rank)\n",
    "\n",
    "    # 4.2 create state encoder\n",
    "    assert args.state_feature_dim is not None, 'please specify state feature dim to create state encoder'\n",
    "    state_encoder = EncoderNetwork(embed_dim=args.state_feature_dim)\n",
    "    state_encoder = state_encoder.to(args.device)\n",
    "\n",
    "    # 4.3 create rl policy\n",
    "    plm_embed_size = cfg.plm_embed_sizes[args.plm_type][args.plm_size]\n",
    "    max_ep_len = exp_dataset_info.max_timestep + 1\n",
    "    rl_policy = OfflineRLPolicy(state_feature_dim=args.state_feature_dim, bitrate_levels=BITRATE_LEVELS, state_encoder=state_encoder, plm=plm, plm_embed_size=plm_embed_size, \n",
    "                                           max_length=args.w, max_ep_len=max_ep_len, device=args.device, device_out=args.device_out, which_layer=args.which_layer)\n",
    "\n",
    "    # 5. handling directory and path\n",
    "\n",
    "    # extract training experience pool information\n",
    "    train_exp_pool_info = args.exp_pool_path.split('/')[-4:-1]\n",
    "    train_exp_pool_info = '_'.join(train_exp_pool_info)\n",
    "    models_dir = os.path.join(cfg.plm_ft_dir, f'{args.plm_type}_{args.plm_size}', train_exp_pool_info + f'_ss_{args.sample_step}', f'rank_{args.rank}_w_{args.w}_gamma_{args.gamma}_sfd_{args.state_feature_dim}'\\\n",
    "                              f'_lr_{args.lr}_wd_{args.weight_decay}_warm_{args.warmup_steps}_epochs_{args.num_epochs}_seed_{args.seed}')\n",
    "    results_dir = os.path.join(cfg.results_dir, f'{args.trace}_{args.video}', f'trace_num_{args.trace_num}_fixed_{args.fixed_order}', f'{args.plm_type}_{args.plm_size}',\n",
    "                               f'early_stop_{args.which_layer}_rank_{args.rank}_w_{args.w}_gamma_{args.gamma}_tgt_scale_{args.target_return_scale}_seed_{args.seed}')\n",
    "    checkpoint_dir = os.path.join(models_dir, f'early_stop_{args.which_layer}_checkpoint')\n",
    "    best_model_dir = os.path.join(models_dir, f'early_stop_{args.which_layer}_best_model')\n",
    "\n",
    "\n",
    "    # 6. start training/testing\n",
    "    def process_reward(reward, \n",
    "                       max_reward=exp_dataset_info.max_reward, \n",
    "                       min_reward=exp_dataset_info.min_reward, \n",
    "                       scale=args.scale):\n",
    "        reward = min(max_reward, max(min_reward, reward))  # bound reward\n",
    "        return (reward - min_reward) / (max_reward - min_reward) / scale\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    if args.adapt:\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        if not os.path.exists(best_model_dir):\n",
    "            os.makedirs(best_model_dir)\n",
    "        console_log = open(os.path.join(models_dir, f'early_stop_{args.which_layer}_console.log'), 'w')\n",
    "        sys.stdout = ConsoleLogger(sys.__stdout__, console_log)\n",
    "        adapt(args, rl_policy, exp_dataset, exp_dataset_info, env_settings, checkpoint_dir, best_model_dir, process_reward)\n",
    "    if args.test:\n",
    "        if not os.path.exists(results_dir):\n",
    "            os.makedirs(results_dir)\n",
    "        model_dir = args.model_dir if args.model_dir is not None else best_model_dir\n",
    "        assert os.path.exists(model_dir), f'Model weight dir {model_dir} does not exist.'\n",
    "        test(args, rl_policy, exp_dataset_info, env_settings, model_dir, results_dir, process_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocation successful!\n",
      "Arguments:\n",
      "Namespace(adapt=True, device='cpu', device_mid=None, device_out='cpu', eval_per_epoch=1, exp_pool_path='artifacts/exp_pools/exp_pool.pkl', fixed_order=True, gamma=1.0, grad_accum_steps=32, lr=0.0001, model_dir=None, num_epochs=1, plm_size='base', plm_type='llama', rank=128, sample_step=10, save_checkpoint_per_epoch=1, scale=1000, seed=100003, state_feature_dim=256, target_return_scale=1.0, test=False, trace='fcc-test', trace_num=100, video='video1', w=20, warmup_steps=2000, weight_decay=0.0001, which_layer=-1)\n",
      "Loading traces from data/traces/test/fcc-test/\n",
      "Experience dataset info:\n",
      "{'max_action': 5,\n",
      " 'max_return': 0.04661987504979122,\n",
      " 'max_reward': 4.3,\n",
      " 'max_timestep': 46,\n",
      " 'min_action': 0,\n",
      " 'min_return': 0.0006304750495579298,\n",
      " 'min_reward': -85.0127377757031,\n",
      " 'min_timestep': 0}\n",
      "model_path ../downloaded_plms\\llama\\base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:55<00:55, 55.91s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from argparse import Namespace\n",
    "\n",
    "def main():\n",
    "    # Set the per-process memory fraction and empty cache\n",
    "    torch.cuda.set_per_process_memory_fraction(0.5, 0)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Test memory allocation\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    try:\n",
    "        x = torch.randn(10000, 10000, device=device)\n",
    "        print(\"Memory allocation successful!\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Memory allocation failed: {e}\")\n",
    "\n",
    "    # # Initialize arguments directly\n",
    "    # args = Namespace(\n",
    "    #     exp_pool_path='artifacts/exp_pools/exp_pool.pkl',\n",
    "    #     sample_step=10,\n",
    "    #     trace='fcc-test',\n",
    "    #     trace_num=100,\n",
    "    #     video='video1',\n",
    "    #     fixed_order=True,\n",
    "    #     plm_type='llama',\n",
    "    #     plm_size='base',\n",
    "    #     rank=128,\n",
    "    #     state_feature_dim=256,\n",
    "    #     w=20,\n",
    "    #     gamma=1.0,\n",
    "    #     lr=1e-4,\n",
    "    #     weight_decay=1e-4,\n",
    "    #     warmup_steps=2000,\n",
    "    #     num_epochs=1,\n",
    "    #     eval_per_epoch=1,\n",
    "    #     save_checkpoint_per_epoch=1,\n",
    "    #     target_return_scale=1.0,\n",
    "    #     which_layer=-1,\n",
    "    #     adapt=True,\n",
    "    #     test=True,\n",
    "    #     grad_accum_steps=32,\n",
    "    #     seed=100003,\n",
    "    #     scale=1000,\n",
    "    #     model_dir=None,\n",
    "    #     device='cuda:0',\n",
    "    #     device_out='cuda:0',\n",
    "    #     device_mid=None\n",
    "    # )\n",
    "    # Initialize arguments directly\n",
    "    args = Namespace(\n",
    "        exp_pool_path='artifacts/exp_pools/exp_pool.pkl',\n",
    "        sample_step=10,\n",
    "        trace='fcc-test',\n",
    "        trace_num=100,\n",
    "        video='video1',\n",
    "        fixed_order=True,\n",
    "        plm_type='llama',\n",
    "        plm_size='base',\n",
    "        rank=128,\n",
    "        state_feature_dim=256,\n",
    "        w=20,\n",
    "        gamma=1.0,\n",
    "        lr=1e-4,\n",
    "        weight_decay=1e-4,\n",
    "        warmup_steps=2000,\n",
    "        num_epochs=1,\n",
    "        eval_per_epoch=1,\n",
    "        save_checkpoint_per_epoch=1,\n",
    "        target_return_scale=1.0,\n",
    "        which_layer=-1,\n",
    "        adapt=True,\n",
    "        test=False,\n",
    "        grad_accum_steps=32,\n",
    "        seed=100003,\n",
    "        scale=1000,\n",
    "        model_dir=None,\n",
    "        device='cpu',\n",
    "        device_out='cpu',\n",
    "        device_mid=None\n",
    "    )\n",
    "\n",
    "    # Print the initialized arguments\n",
    "    print('Arguments:')\n",
    "    print(args)\n",
    "\n",
    "    # Call the run function with the initialized arguments\n",
    "    run(args)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urllc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
